{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "<img src=\"images/RL.png\" width=400>\n",
    "\n",
    "\n",
    "<b>Agent:</b> A cute robot. The goal of the agent is to pick the best policy that will maximize the total rewards received from the environment.\n",
    "<img src=\"images/walle.png\" width=100>\n",
    "\n",
    "<b>Environment:</b> The world the Agent interacts with.\n",
    "\n",
    "<b>State:</b>  $S(t)$ The current configuration of the environment.\n",
    "\n",
    "<b>Action:</b> $A(t)$ Things agent can do that will affect its state.\n",
    "\n",
    "<b>Reward:</b> $R(t)$ Result of the action. Can be negative or positive. Represents how good the action was. \n",
    "\n",
    "<b>Policy:</b> Final working strategy the Agent identifies. A function that takes the current environment state to return an action.\n",
    "$\\pi(s): S -> R$\n",
    "\n",
    "<b>Episode:</b> Represents one run of the game. The Agent learns across many epizodes. # of episodes used to train is a hyperparameter. \n",
    "\n",
    "<b>Terminal State:</b> End state after an episode.\n",
    "\n",
    "Where $t$ is time-step t.\n",
    "\n",
    "An action durring a state results in a reward for that action and a new updated state.\n",
    "$S(t), A(t) -> R(t+1),S(t+1)$\n",
    "This is also represented by a 4-tuple with the notation $(s, a, r, s')$.\n",
    "\n",
    "\n",
    "\n",
    "<b>Value Function:</b> $V(S)$ the value of a state that considers future rewards as well as immediate rewards. It is the value of a state that takes into account the probability of all possible future rewards. \n",
    "Each state will have a value that is based on all possible future rewards.  Tells you how valueable being in a state is by taking into consideration possible future rewards. \n",
    "$V(S) = E(all future rewards | S(t)=s)$\n",
    "\n",
    "<b>Attribution</b> How to attribute rewards to actions such that long term rewards are considered. \n",
    "\n",
    "<b>Total Discounted Reward</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class TicTacToe():\n",
    "    def __init__(self, eps, V1=None, V2=None, plots=True):\n",
    "        self.p1_actions = []\n",
    "        self.p2_actions = []\n",
    "        self.past_actions = []\n",
    "        self.winner = None\n",
    "        self.V1 = V1\n",
    "        self.V2 = V2\n",
    "        self.eps = eps\n",
    "        self.plots = plots\n",
    "        self.player_turn = None\n",
    "        if self.plots == True:\n",
    "            self.drawboard()\n",
    "            \n",
    "    def play(self):\n",
    "        \n",
    "        check_game = self.game_over()\n",
    "        while not check_game:\n",
    "            self.player_turn=\"p1\"\n",
    "            self.update_board()\n",
    "            check_game = self.game_over()\n",
    "            if not check_game:\n",
    "                self.player_turn=\"p2\"\n",
    "                self.update_board()\n",
    "                check_game = self.game_over()\n",
    "            else:\n",
    "                return \n",
    "        else:\n",
    "            return\n",
    "    \n",
    "    def drawboard(self):\n",
    "        try:\n",
    "            for i in range(len(self.p1_actions)):\n",
    "                plt.plot(self.p1_actions[i][0], self.p1_actions[i][1], 'ro', color=\"red\")\n",
    "        except:\n",
    "            plt.plot([], 'ro', color=\"red\")\n",
    "        try:\n",
    "            for i in range(len(self.p2_actions)):\n",
    "                plt.plot(self.p2_actions[i][0], self.p2_actions[i][1], 'v', color=\"blue\")\n",
    "        except:\n",
    "             plt.plot([], 'v', color=\"blue\")\n",
    "                \n",
    "        plt.xlim([0, 6])\n",
    "        plt.ylim([0, 6])\n",
    "        plt.axvline(x=2, color=\"black\")\n",
    "        plt.axvline(x=4, color=\"black\")\n",
    "        plt.axhline(y=2, color=\"black\")\n",
    "        plt.axhline(y=4, color=\"black\")\n",
    "\n",
    "    \n",
    "    def update_state(self, state):\n",
    "        \n",
    "        #select action\n",
    "        new_x, new_y = self.get_next_coordinates()\n",
    "        while ((new_x, new_y) in self.past_actions):\n",
    "            new_x, new_y = self.get_next_coordinates()\n",
    "        \n",
    "        #update state with action\n",
    "        else:\n",
    "            state.append((new_x,new_y))\n",
    "            self.past_actions.append((new_x,new_y))\n",
    "            \n",
    "        return state\n",
    "    \n",
    "    def get_next_coordinates(self):\n",
    "        r = np.random.rand()\n",
    "        #explore\n",
    "        #randomly select a point on the board\n",
    "        if r < self.eps:\n",
    "            new_x = np.random.choice([1, 3, 5], 1)[0]\n",
    "            new_y = np.random.choice([1, 3, 5], 1)[0]\n",
    "        #exploit\n",
    "        #select a point on the board according to value function V\n",
    "        else:\n",
    "            #remove points already played\n",
    "            if self.player_turn == \"p1\":\n",
    "                self.V1[~self.V1.index.isin(self.past_actions)]\n",
    "                #select best point remaining\n",
    "                new_x = self.V1.idxmax()[0][0]\n",
    "                new_y = self.V1.idxmax()[0][1]\n",
    "            else:\n",
    "                self.V2[~self.V2.index.isin(self.past_actions)]\n",
    "                #select best point remaining\n",
    "                new_x = self.V2.idxmax()[0][0]\n",
    "                new_y = self.V2.idxmax()[0][1]\n",
    "        return new_x, new_y\n",
    "\n",
    "\n",
    "    def update_board(self):\n",
    "        \n",
    "        if self.player_turn == \"p1\":\n",
    "            self.p1_actions = self.update_state(self.p1_actions)\n",
    "        else:\n",
    "            self.p2_actions = self.update_state(self.p2_actions) \n",
    "        \n",
    "        if self.plots == True:\n",
    "            self.drawboard()\n",
    "            display(plt)\n",
    "            clear_output(wait = True)\n",
    "            plt.pause(0.5)\n",
    "        \n",
    "    def game_over(self):\n",
    "    \n",
    "        #diagonal wins\n",
    "        diagonal_win_a = [(1, 5), (3, 3), (5, 1)]\n",
    "        if (set(diagonal_win_a) <= set(self.p1_actions)):\n",
    "            self.winner = \"p1\"\n",
    "            return True\n",
    "        if (set(diagonal_win_a) <= set(self.p2_actions)):\n",
    "            self.winner = \"p2\"\n",
    "            return True\n",
    "        diagonal_win_b = [(5, 1), (3, 3), (1, 5)]\n",
    "        if (set(diagonal_win_b) <= set(self.p1_actions)):\n",
    "            self.winner = \"p1\"\n",
    "            return True\n",
    "        if (set(diagonal_win_b) <= set(self.p2_actions)):\n",
    "            self.winner = \"p2\"\n",
    "            return True\n",
    "            \n",
    "        \n",
    "        #vertical wins\n",
    "        vertical_win_a = [(1,1), (1,3), (1,5)]\n",
    "        vertical_win_b = [(3,1), (3,3), (3,5)]\n",
    "        vertical_win_c = [(5,1), (5,3), (5,5)]\n",
    "        if (set(vertical_win_a) <= set(self.p1_actions)):\n",
    "            self.winner = \"p1\"\n",
    "            return True\n",
    "        if (set(vertical_win_a) <= set(self.p2_actions)):\n",
    "            self.winner = \"p2\"\n",
    "            return True\n",
    "        if (set(vertical_win_b) <= set(self.p1_actions)):\n",
    "            self.winner = \"p1\"\n",
    "            return True\n",
    "        if (set(vertical_win_b) <= set(self.p2_actions)):\n",
    "            self.winner = \"p2\"\n",
    "            return True\n",
    "        if (set(vertical_win_c) <= set(self.p1_actions)):\n",
    "            self.winner = \"p1\"\n",
    "            return True\n",
    "        if (set(vertical_win_c) <= set(self.p2_actions)):\n",
    "            self.winner = \"p2\"\n",
    "            return True\n",
    "\n",
    "    \n",
    "        #horizontal wins\n",
    "        horizontal_win_a = [(1,1), (3,1), (5,1)]\n",
    "        horizontal_win_b = [(1,3), (3,3), (5,3)]\n",
    "        horizontal_win_c = [(1,5), (3,5), (5,5)]\n",
    "        if (set(horizontal_win_a) <= set(self.p1_actions)):\n",
    "            self.winner = \"p1\"\n",
    "            return True\n",
    "        if (set(horizontal_win_a) <= set(self.p2_actions)):\n",
    "            self.winner = \"p2\"\n",
    "            return True\n",
    "        if (set(horizontal_win_b) <= set(self.p1_actions)):\n",
    "            self.winner = \"p1\"\n",
    "            return True\n",
    "        if (set(horizontal_win_b) <= set(self.p2_actions)):\n",
    "            self.winner = \"p2\"\n",
    "            return True\n",
    "        if (set(horizontal_win_c) <= set(self.p1_actions)):\n",
    "            self.winner = \"p1\"\n",
    "            return True\n",
    "        if (set(horizontal_win_c) <= set(self.p2_actions)):\n",
    "            self.winner = \"p2\"\n",
    "            return True\n",
    "        \n",
    "        \n",
    "        if len(self.past_actions) >= 9:\n",
    "            return True\n",
    "        \n",
    "        else: \n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps = 1\n",
    "game = TicTacToe(eps=1)\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cute_Robot():\n",
    "    '''Agent class that plays TicTacToe episodes to learn a policy. \n",
    "    Uses Epsilon Greedy.'''\n",
    "    \n",
    "    def __init__(self, player, alpha):\n",
    "        self.alpha = alpha # learning rate\n",
    "        self.player = player\n",
    "        self.V = self.init_V()\n",
    "        self.actions = None\n",
    "        self.winner = None\n",
    "    \n",
    "    \n",
    "    def init_V(self): \n",
    "        '''Initialize value function based on outcome of one initial game.\n",
    "        Value function is a function of all possible states.\n",
    "        Im using places on the board as statees isntead of all possible configurations of the board for simplicity.'''\n",
    "\n",
    "        game = TicTacToe(eps=1, plots=False)\n",
    "        game.play()\n",
    "        \n",
    "        V = pd.DataFrame([0.5]*9, index=[(1,1), (1,3), (1,5), (3,1), (3,3), (3,5), (5,1), (5,3), (5,5)]) \n",
    "        \n",
    "        if game.winner == self.player:\n",
    "            V = pd.DataFrame([1]*9, index=[(1,1), (1,3), (1,5), (3,1), (3,3), (3,5), (5,1), (5,3), (5,5)])\n",
    "\n",
    "        if (game.winner != None) and (game.winner != self.player): \n",
    "            V = pd.DataFrame([0]*9, index=[(1,1), (1,3), (1,5), (3,1), (3,3), (3,5), (5,1), (5,3), (5,5)])\n",
    "\n",
    "        return V\n",
    "\n",
    "    def update_value_function(self):\n",
    "        '''backprob through state history to calc the value function.\n",
    "        v(s) = v(s) + alpha(v(s')-v(s))\n",
    "        '''\n",
    "        reward = 0.5\n",
    "        if self.winner == self.player:\n",
    "            reward = 1\n",
    "        if (self.winner != None) and (self.winner != self.player):\n",
    "            reward = 0\n",
    "\n",
    "        target = reward\n",
    "\n",
    "        for prev in reversed(self.actions):\n",
    "            value = self.V.loc[[prev]][0][0] + self.alpha*(target - self.V.loc[[prev]][0][0])\n",
    "            self.V.loc[[prev]] = value\n",
    "            target = value\n",
    "\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Play two agents against eachother so each one learns a value function.\n",
    "\n",
    "# initialize the agents\n",
    "Agent_1 = Cute_Robot(alpha=0.5, player=\"p1\")\n",
    "Agent_2 = Cute_Robot(alpha=0.5, player=\"p2\")\n",
    "\n",
    "\n",
    "#play some episodes\n",
    "T = 1000\n",
    "eps = 0.5\n",
    "for t in range(T):\n",
    "    #play a game\n",
    "    game = TicTacToe(V1=Agent_1.V, V2=Agent_2.V, eps=eps, plots=False)\n",
    "    game.play()\n",
    "    #update Agent's states\n",
    "    Agent_1.actions = game.p1_actions\n",
    "    Agent_1.winner = game.winner\n",
    "    Agent_2.actions = game.p2_actions\n",
    "    Agent_2.winner = game.winner\n",
    "    #update Agent's value functions\n",
    "    Agent_1.update_value_function()\n",
    "    Agent_2.update_value_function()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(1, 1)</th>\n",
       "      <td>0.592875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 3)</th>\n",
       "      <td>0.542990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 5)</th>\n",
       "      <td>0.749371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(3, 1)</th>\n",
       "      <td>0.579017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(3, 3)</th>\n",
       "      <td>0.424163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(3, 5)</th>\n",
       "      <td>0.748032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(5, 1)</th>\n",
       "      <td>0.679286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(5, 3)</th>\n",
       "      <td>0.540169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(5, 5)</th>\n",
       "      <td>0.747896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "(1, 1)  0.592875\n",
       "(1, 3)  0.542990\n",
       "(1, 5)  0.749371\n",
       "(3, 1)  0.579017\n",
       "(3, 3)  0.424163\n",
       "(3, 5)  0.748032\n",
       "(5, 1)  0.679286\n",
       "(5, 3)  0.540169\n",
       "(5, 5)  0.747896"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agent_1.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(1, 1)</th>\n",
       "      <td>0.163480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 3)</th>\n",
       "      <td>0.386499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 5)</th>\n",
       "      <td>0.373980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(3, 1)</th>\n",
       "      <td>0.260334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(3, 3)</th>\n",
       "      <td>0.283148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(3, 5)</th>\n",
       "      <td>0.376796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(5, 1)</th>\n",
       "      <td>0.379136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(5, 3)</th>\n",
       "      <td>0.360837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(5, 5)</th>\n",
       "      <td>0.322933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "(1, 1)  0.163480\n",
       "(1, 3)  0.386499\n",
       "(1, 5)  0.373980\n",
       "(3, 1)  0.260334\n",
       "(3, 3)  0.283148\n",
       "(3, 5)  0.376796\n",
       "(5, 1)  0.379136\n",
       "(5, 3)  0.360837\n",
       "(5, 5)  0.322933"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agent_2.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender_engines",
   "language": "python",
   "name": "recommender_engines"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
